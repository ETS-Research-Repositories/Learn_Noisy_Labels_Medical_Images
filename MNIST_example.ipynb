{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import torch\n",
    "import timeit\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from adamW import AdamW\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "from Loss import noisy_label_loss\n",
    "from Utilis import segmentation_scores, CustomDataset_punet, calculate_cm\n",
    "from Utilis import evaluate_noisy_label_4, evaluate_noisy_label_5, evaluate_noisy_label_6\n",
    "# our proposed model:\n",
    "from Models import UNet_CMs\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= #\n",
    "# Hyper-parameters setting\n",
    "# ========================= #\n",
    "\n",
    "# hyper-parameters for model:\n",
    "input_dim = 3 # dimension of input\n",
    "width = 24 # width of the network\n",
    "depth = 3 # depth of the network, downsampling times is (depth-1)\n",
    "class_no = 2 # class number, 2 for binary\n",
    "\n",
    "# hyper-parameters for training:\n",
    "train_batchsize = 5 # batch size\n",
    "alpha = 0.001 # weight of the trace regularisation of learnt confusion matrices\n",
    "num_epochs = 40 # total epochs\n",
    "learning_rate = 1e-2 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x936 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ======================================= #\n",
    "# Prepare a few data examples from MNIST \n",
    "# ======================================= #\n",
    "\n",
    "# Change path for your own datasets here:\n",
    "data_path = './MNIST_examples'\n",
    "dataset_tag = 'mnist'\n",
    "label_mode = 'multi'\n",
    "\n",
    "# full path to train/validate/test:\n",
    "test_path = data_path + '/test' \n",
    "train_path = data_path + '/train'\n",
    "validate_path = data_path + '/validate'\n",
    "\n",
    "# prepare data sets using our customdataset\n",
    "train_dataset = CustomDataset_punet(dataset_location=train_path, dataset_tag=dataset_tag, noisylabel=label_mode, augmentation=True)\n",
    "validate_dataset = CustomDataset_punet(dataset_location=validate_path, dataset_tag=dataset_tag, noisylabel=label_mode, augmentation=False)\n",
    "test_dataset = CustomDataset_punet(dataset_location=test_path, dataset_tag=dataset_tag, noisylabel=label_mode, augmentation=False)\n",
    "\n",
    "# putting dataset into data loaders\n",
    "trainloader = data.DataLoader(train_dataset, batch_size=train_batchsize, shuffle=True, num_workers=2, drop_last=True)\n",
    "validateloader = data.DataLoader(validate_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "testloader = data.DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "# demonstrate the training samples:\n",
    "Image_index_to_demonstrate = 6\n",
    "images, labels_over, labels_under, labels_wrong, labels_good, imagename = validate_dataset[Image_index_to_demonstrate]\n",
    "images = np.mean(images, axis=0)\n",
    "# print('The dimension of image, channel:' + str(np.shape(images)[0]) + ', height:' + str(np.shape(images)[1]) + ', width:' + str(np.shape(images)[2]))\n",
    "# print('The dimension of label, channel:' + str(np.shape(labels_over)[0]) + ', height:' + str(np.shape(labels_over)[1]) + ', width:' + str(np.shape(labels_over)[2]))\n",
    "\n",
    "# plot input image:\n",
    "# the input image is original mnist images with gaussian noises\n",
    "# plt.imshow(np.mean(images, axis=0), cmap='gray')\n",
    "# plt.title('Input image')\n",
    "# plt.show()\n",
    "\n",
    "# plot the labels:\n",
    "fig = plt.figure(figsize=(9, 13))\n",
    "columns = 5\n",
    "rows = 1\n",
    "ax = []\n",
    "labels = []\n",
    "labels_names = []\n",
    "labels.append(images)\n",
    "labels.append(labels_over)\n",
    "labels.append(labels_under)\n",
    "labels.append(labels_wrong)\n",
    "labels.append(labels_good)\n",
    "labels_names.append('Input')\n",
    "labels_names.append('Over label')\n",
    "labels_names.append('Under label')\n",
    "labels_names.append('Wrong label')\n",
    "labels_names.append('Good label')\n",
    "\n",
    "for i in range(columns*rows):\n",
    "    if i != 0:\n",
    "        label_ = labels[i][0, :, :]\n",
    "    else:\n",
    "        label_ = labels[i]\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "    ax[-1].set_title(labels_names[i]) \n",
    "    plt.imshow(label_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== #\n",
    "# Model\n",
    "# ===== #\n",
    "\n",
    "# call model:\n",
    "model = UNet_CMs(in_ch=input_dim, width=width, depth=depth, class_no=class_no, norm='in', low_rank=False)\n",
    "\n",
    "# model name for saving:\n",
    "model_name = 'UNet_Confusion_Matrices_' + '_width' + str(width) + \\\n",
    "           '_depth' + str(depth) + '_train_batch_' + str(train_batchsize) + \\\n",
    "           '_alpha_' + str(alpha) + '_e' + str(num_epochs) + \\\n",
    "           '_lr' + str(learning_rate) \n",
    "\n",
    "# setting up device:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================== #\n",
    "# Prepare folders to save trained models and results \n",
    "# =================================================== #\n",
    "\n",
    "# save location:\n",
    "saved_information_path = './Results'\n",
    "try:\n",
    "    os.mkdir(saved_information_path)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "saved_information_path = saved_information_path + '/' + model_name\n",
    "try:\n",
    "    os.mkdir(saved_information_path)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "saved_model_path = saved_information_path + '/trained_models'\n",
    "try:\n",
    "    os.mkdir(saved_model_path)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "save_path_visual_result = saved_information_path + '/visual_results'\n",
    "try:\n",
    "    os.mkdir(save_path_visual_result)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "# tensorboardX file saved location:\n",
    "writer = SummaryWriter('./Results/Log_' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================== #\n",
    "# Training\n",
    "# =================================================== #\n",
    "\n",
    "# We use adamW optimiser for more accurate L2 regularisation\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_loss_ce = 0\n",
    "    running_loss_trace = 0\n",
    "    running_iou = 0\n",
    "    \n",
    "    for j, (images, labels_over, labels_under, labels_wrong, labels_good, imagename) in enumerate(trainloader):\n",
    "        \n",
    "        b, c, h, w = images.size()\n",
    "        \n",
    "        # zero graidents before each iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # cast numpy data into tensor float\n",
    "        images = images.to(device=device, dtype=torch.float32)\n",
    "        labels_over = labels_over.to(device=device, dtype=torch.float32)\n",
    "        labels_under = labels_under.to(device=device, dtype=torch.float32)\n",
    "        labels_wrong = labels_wrong.to(device=device, dtype=torch.float32)\n",
    "        labels_good = labels_good.to(device=device, dtype=torch.float32)\n",
    "        \n",
    "        labels_all = []\n",
    "        labels_all.append(labels_over)\n",
    "        labels_all.append(labels_under)\n",
    "        labels_all.append(labels_wrong)\n",
    "        labels_all.append(labels_good)\n",
    "        \n",
    "        # model has two outputs: \n",
    "        # first one is the probability map for true ground truth \n",
    "        # second one is a list collection of probability maps for different noisy ground truths\n",
    "        outputs_logits, outputs_logits_noisy = model(images)\n",
    "        \n",
    "        # calculate loss:\n",
    "        # loss: total loss\n",
    "        # loss_ce: main cross entropy loss\n",
    "        # loss_trace: regularisation loss\n",
    "        loss, loss_ce, loss_trace = noisy_label_loss(outputs_logits, outputs_logits_noisy, labels_all, alpha)\n",
    "\n",
    "        # calculate the gradients:\n",
    "        loss.backward()\n",
    "        # update weights in model:\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, train_output = torch.max(outputs_logits, dim=1)\n",
    "        train_iou = segmentation_scores(labels_good.cpu().detach().numpy(), train_output.cpu().detach().numpy(), class_no)\n",
    "        running_loss += loss\n",
    "        running_loss_ce += loss_ce\n",
    "        running_loss_trace += loss_trace\n",
    "        running_iou += train_iou\n",
    "\n",
    "        if (j + 1) == 1:\n",
    "            # check the validation accuray at the begning of each epoch:\n",
    "            v_dice, v_ged = evaluate_noisy_label_4(data=validateloader,\n",
    "                                                   model1=model,\n",
    "                                                   class_no=class_no)\n",
    "            \n",
    "            print(\n",
    "                'Step [{}/{}], '\n",
    "                'Val dice: {:.4f},'\n",
    "                'Val GED: {:.4f},'\n",
    "                'loss main: {:.4f},'\n",
    "                'loss regualrisation: {:.4f},'.format(epoch + 1, num_epochs,\n",
    "                                                            v_dice,\n",
    "                                                            v_ged,\n",
    "                                                            running_loss_ce / (j + 1),\n",
    "                                                            running_loss_trace / (j + 1)))\n",
    "        \n",
    "            writer.add_scalars('scalars', {'loss': running_loss / (j + 1),\n",
    "                                           'train iou': running_iou / (j + 1),\n",
    "                                           'val iou': v_dice,\n",
    "                                           'train main loss': running_loss_ce / (j + 1),\n",
    "                                           'train regularisation loss': running_loss_trace / (j + 1)}, epoch + 1)\n",
    "\n",
    "# save model:\n",
    "save_model_name_full = saved_model_path + '/' + model_name + '_Final.pt'\n",
    "torch.save(model, save_model_name_full)\n",
    "print('\\n')\n",
    "print('Training ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================== #\n",
    "# Testing\n",
    "# =================================================== #\n",
    "model.eval()\n",
    "for i, (v_images, labels_over, labels_under, labels_wrong, labels_good, imagename) in enumerate(testloader):\n",
    "        v_images = v_images.to(device=device, dtype=torch.float32)\n",
    "        v_outputs_logits_original, v_outputs_logits_noisy = model(v_images)\n",
    "        b, c, h, w = v_outputs_logits_original.size()\n",
    "        # plot the final segmentation map\n",
    "        v_outputs_logits_original = nn.Softmax(dim=1)(v_outputs_logits_original)\n",
    "        _, v_outputs_logits = torch.max(v_outputs_logits_original, dim=1)\n",
    "\n",
    "        save_name = save_path_visual_result + '/test_' + str(i) + '_seg.png'\n",
    "        save_name_label = save_path_visual_result + '/test_' + str(i) + '_label.png'\n",
    "        save_name_slice = save_path_visual_result + '/test_' + str(i) + '_img.png'\n",
    "\n",
    "        plt.imsave(save_name_slice, v_images[:, 1, :, :].reshape(h, w).cpu().detach().numpy(), cmap='gray')\n",
    "        plt.imsave(save_name, v_outputs_logits.reshape(h, w).cpu().detach().numpy(), cmap='gray')\n",
    "        plt.imsave(save_name_label, labels_good.reshape(h, w).cpu().detach().numpy(), cmap='gray')\n",
    "        \n",
    "        # plot the noisy segmentation maps:\n",
    "        v_outputs_logits_original = v_outputs_logits_original.reshape(b, c, h*w)\n",
    "        v_outputs_logits_original = v_outputs_logits_original.permute(0, 2, 1).contiguous()\n",
    "        v_outputs_logits_original = v_outputs_logits_original.view(b * h * w, c).view(b*h*w, c, 1)\n",
    "        for j, cm in enumerate(v_outputs_logits_noisy):\n",
    "            cm = cm.view(b, c**2, h*w).permute(0, 2, 1).contiguous().view(b*h*w, c*c).view(b*h*w, c, c)\n",
    "            cm = cm / cm.sum(1, keepdim=True)\n",
    "            v_noisy_output_original = torch.bmm(cm, v_outputs_logits_original).view(b*h*w, c)\n",
    "            v_noisy_output_original = v_noisy_output_original.view(b, h*w, c).permute(0, 2, 1).contiguous().view(b, c, h, w)\n",
    "            _, v_noisy_output = torch.max(v_noisy_output_original, dim=1)\n",
    "            save_name = save_path_visual_result + '/test_' + str(i) + '_noisy_' + str(j) + '_seg.png'\n",
    "            plt.imsave(save_name, v_noisy_output.reshape(h, w).cpu().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================== #\n",
    "# Predictions Plot\n",
    "# =================================================== #\n",
    "test_data_index = 15\n",
    "\n",
    "over_seg = save_path_visual_result + '/test_' + str(test_data_index) + '_noisy_' + str(0) + '_seg.png'\n",
    "under_seg = save_path_visual_result + '/test_' + str(test_data_index) + '_noisy_' + str(1) + '_seg.png'\n",
    "wrong_seg = save_path_visual_result + '/test_' + str(test_data_index) + '_noisy_' + str(2) + '_seg.png'\n",
    "good_seg = save_path_visual_result + '/test_' + str(test_data_index) + '_noisy_' + str(3) + '_seg.png'\n",
    "\n",
    "seg = save_path_visual_result + '/test_' + str(test_data_index) + '_seg.png'\n",
    "label = save_path_visual_result + '/test_' + str(test_data_index) + '_label.png'\n",
    "img = save_path_visual_result + '/test_' + str(test_data_index) + '_img.png'\n",
    "\n",
    "# plot image, ground truth and final segmentation\n",
    "fig = plt.figure(figsize=(6.7, 13))\n",
    "columns = 3\n",
    "rows = 1\n",
    "\n",
    "ax = []\n",
    "imgs = []\n",
    "imgs_names = []\n",
    "\n",
    "imgs.append(img)\n",
    "imgs.append(label)\n",
    "imgs.append(seg)\n",
    "\n",
    "imgs_names.append('Test img')\n",
    "imgs_names.append('GroundTruth')\n",
    "imgs_names.append('Pred of true seg')\n",
    "\n",
    "for i in range(columns*rows):\n",
    "    img_ = imgs[i]\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "    ax[-1].set_title(imgs_names[i]) \n",
    "    img_ = Image.open(img_)\n",
    "    img_ = np.array(img_, dtype='uint8')\n",
    "    plt.imshow(img_, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# plot the segmentation for noisy labels:\n",
    "fig = plt.figure(figsize=(9, 13))\n",
    "columns = 4\n",
    "rows = 1\n",
    "\n",
    "ax = []\n",
    "noisy_segs = []\n",
    "noisy_segs_names = []\n",
    "\n",
    "noisy_segs.append(over_seg)\n",
    "noisy_segs.append(under_seg)\n",
    "noisy_segs.append(wrong_seg)\n",
    "noisy_segs.append(good_seg)\n",
    "\n",
    "noisy_segs_names.append('Pred of over')\n",
    "noisy_segs_names.append('Pred of under')\n",
    "noisy_segs_names.append('Pred of wrong')\n",
    "noisy_segs_names.append('Pred of good')\n",
    "\n",
    "for i in range(columns*rows):\n",
    "    noisy_seg_ = noisy_segs[i]\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "    ax[-1].set_title(noisy_segs_names[i]) \n",
    "    noisy_seg_ = Image.open(noisy_seg_)\n",
    "    noisy_seg_ = np.array(noisy_seg_, dtype='uint8' )\n",
    "    plt.imshow(noisy_seg_, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
